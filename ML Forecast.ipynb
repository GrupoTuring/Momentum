{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Classification ML Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "\n",
    "def import_data(csv): \n",
    "    \n",
    "    df = pd.read_csv(csv)\n",
    "    df.index = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    close_columns = []\n",
    "    high_columns = []\n",
    "    low_columns = []\n",
    "    open_columns = []\n",
    "    volume_columns = []\n",
    "    open_int_columns = []\n",
    "\n",
    "    for i in df.columns:\n",
    "        if \"close\" in i:\n",
    "            close_columns.append(i)\n",
    "        elif \"high\" in i:\n",
    "            high_columns.append(i)\n",
    "        elif \"low\" in i:\n",
    "            low_columns.append(i)\n",
    "        elif \"open_int\" in i:\n",
    "            open_int_columns.append(i)\n",
    "        elif \"open\" in i:\n",
    "            open_columns.append(i)\n",
    "        elif \"volume\" in i:\n",
    "            volume_columns.append(i)\n",
    "\n",
    "    close_df = df[close_columns]\n",
    "    high_df = df[high_columns]\n",
    "    low_df = df[low_columns]\n",
    "    open_df = df[open_columns]\n",
    "    volume_df = df[volume_columns]\n",
    "    open_int_df = df[open_int_columns]\n",
    "    \n",
    "    return [close_df, high_df, low_df, open_df, volume_df, open_int_df]\n",
    "\n",
    "def garman_klass_vol(high_df, low_df, close_df, open_df, period=60):\n",
    "    \"\"\"\n",
    "    Estima a volatilidade a partir dos seguintes preços: alta, baixa, abertura e fechamento\n",
    "    \"\"\"\n",
    "    # Calculando parcelas internas da somatoria\n",
    "    x_hl = (1/2)*(np.log(np.divide(high_df, low_df))) ** 2\n",
    "    x_co = - (2 * np.log(2) - 1)* (np.log(np.divide(close_df, open_df))**2)\n",
    "    \n",
    "    # Somando parcelas calculadas\n",
    "    x = x_hl + x_co.values\n",
    "    \n",
    "    x.columns = [x[0:3] + \"gk\" for x in x.columns]\n",
    "    \n",
    "    # Criando dataframe para atribuir as volatilidades\n",
    "    gk = x.copy()\n",
    "    \n",
    "    # Termo constante fora da somatoria (Considerando vol diaria)\n",
    "    const = 1/period\n",
    "    \n",
    "    # Atribuindo not a number, para os valores iniciais\n",
    "    gk.iloc[:period,:] = np.nan\n",
    "    \n",
    "    # iteração do centro de massa da vol\n",
    "    for row in range(period, len(high_df)):\n",
    "        gk.iloc[row] = np.sqrt(const * np.sum(x.iloc[row-period:row,:]))\n",
    "        \n",
    "    return gk\n",
    "\n",
    "def parkinson_vol(high_df, low_df, period=60):\n",
    "    \"\"\"\n",
    "    Estimando a volatilidade a partir dos preço de Alta e de Baixa\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculando parcela interna da somatoria\n",
    "    x = np.log(np.divide(high_df, low_df)) ** 2\n",
    "    x.columns = [x[0:3] + \"pv\" for x in x.columns]\n",
    "    \n",
    "    # Criando dataframe para atribuir as volatilidades\n",
    "    pv = x.copy()\n",
    "    \n",
    "    # Termo constante fora da somatoria (Considerando vol diaria)\n",
    "    const = 1 / (4 * period * np.log(2))\n",
    "    \n",
    "    # Atribuindo not a number, para os valores iniciais\n",
    "    pv.iloc[:period,:] = np.nan\n",
    "        \n",
    "    # iteração do centro de massa da vol\n",
    "    for row in range(period, len(high_df)):\n",
    "        pv.iloc[row] = np.sqrt(const * np.sum(x.iloc[row-period:row,:]))\n",
    "        \n",
    "    return pv\n",
    "\n",
    "def monthly_volume(volume, period=20):\n",
    "    \n",
    "    daily_volume = volume.copy()\n",
    "    \n",
    "    for row in range(period, len(volume)):\n",
    "        daily_volume.iloc[row] = volume.iloc[row-period:row,:].cumsum().iloc[-1]\n",
    "        \n",
    "    monthly_volume = daily_volume.resample(\"BM\").last().ffill()\n",
    "    \n",
    "    return monthly_volume\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df, high_df, low_df, open_df, volume_df, open_int_df = import_data(\"data.csv\")\n",
    "\n",
    "# Retornos diários\n",
    "returns_daily = close_df.pct_change().fillna(0)\n",
    "\n",
    "# Retornos mensais\n",
    "returns_monthly = close_df.pct_change(20).fillna(0).resample('BM').last().ffill()\n",
    "\n",
    "# Vol diária\n",
    "vol_daily = returns_daily.ewm(adjust=True, com=60, min_periods=0).std().dropna()\n",
    "\n",
    "# Vol de 261 dias, apenas o último dia de cada mês\n",
    "vol_monthly = (np.sqrt(261)*vol_daily).resample('BM').last().ffill()\n",
    "\n",
    "pv_df = parkinson_vol(high_df, low_df)\n",
    "pv_monthly = (np.sqrt(261)*pv_df).resample('BM').last().ffill()\n",
    "\n",
    "gk_df = garman_klass_vol(high_df, low_df, close_df, open_df)\n",
    "gk_monthly = (np.sqrt(261)*gk_df).resample('BM').last().ffill()\n",
    "\n",
    "monthly_volume = monthly_volume(volume_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(stock):\n",
    "    train = pd.DataFrame()\n",
    "\n",
    "    stock = 10\n",
    "\n",
    "    train[\"Returns Monthly\"] = returns_monthly.iloc[:,stock]\n",
    "    train[\"EWMA Monthly\"] = vol_monthly.iloc[:,stock]\n",
    "    train[\"Parkinson\"] = pv_monthly.iloc[:,stock]\n",
    "    train[\"Garman-Klass\"] = gk_monthly.iloc[:,stock]\n",
    "    train[\"Monthly Volume\"] = monthly_volume.iloc[:,stock]\n",
    "\n",
    "    prices = close_df.iloc[:,stock]\n",
    "\n",
    "    for lag in [3, 6, 9, 12]:\n",
    "        train[\"Lagged Momentum \" + str(lag)] = prices.pct_change(lag * 21)\n",
    "\n",
    "    target = train[\"Returns Monthly\"].shift(-1)\n",
    "    \n",
    "    features = train.dropna()\n",
    "    target = test.dropna().loc['2000-07-31':]\n",
    "    \n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesting(model, name=\"MODEL\"):\n",
    "    momentum = []\n",
    "    prediction = []\n",
    "    real = []\n",
    "\n",
    "\n",
    "    for stock in range(54):\n",
    "\n",
    "        printProgressBar(stock, 53)\n",
    "\n",
    "        features, target = train_test(stock)\n",
    "\n",
    "        pred = []\n",
    "        true = []\n",
    "        mom = []\n",
    "\n",
    "        for date in range(100,190):\n",
    "            \n",
    "            # **TRAIN DATA**\n",
    "            # Features\n",
    "            X = features.dropna().iloc[date-36:date]\n",
    "            \n",
    "            # Target\n",
    "            y = np.sign(target.dropna().iloc[date-36:date])\n",
    "\n",
    "            # **TEST DATA**\n",
    "            # Features\n",
    "            X_test = features.dropna().iloc[date:date+1]\n",
    "            \n",
    "            # Target\n",
    "            y_test = np.sign(target.dropna().iloc[date:date+1])\n",
    "\n",
    "            # Fitting the model\n",
    "            model.fit(X, y)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            pred.append(y_pred[0])\n",
    "            true.append(y_test[0])\n",
    "            mom.append(np.sign(train[\"Lagged Momentum 12\"].iloc[date-1]))\n",
    "\n",
    "        momentum.append(mom)\n",
    "        prediction.append(pred)\n",
    "        real.append(true)\n",
    "\n",
    "    mom_array = np.array(momentum)\n",
    "    pred_array = np.array(prediction)\n",
    "    real_array = np.array(real)\n",
    "    \n",
    "    \n",
    "    # Reshaping\n",
    "    true = real_array.reshape([54*90, 1])\n",
    "    pred = pred_array.reshape([54*90, 1])\n",
    "    mom = mom_array.reshape([54*90, 1])\n",
    "\n",
    "    model_ac = accuracy_score(true, pred)\n",
    "    model_f1 = f1_score(true, pred)\n",
    "\n",
    "    mom_ac = accuracy_score(true, mom)\n",
    "    mom_f1 = f1_score(true, mom)\n",
    "\n",
    "    print(\"MOMENTUM\")\n",
    "    print( \"Accuracy: \", mom_ac)\n",
    "    print(\"F1 Score: \", mom_f1)\n",
    "    print()\n",
    "    print(name)\n",
    "    print(\"Accuracy: \", model_ac)\n",
    "    print(\"F1 Score: \", model_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "MOMENTUM\n",
      "Accuracy:  0.5333333333333333\n",
      "F1 Score:  0.6315789473684211\n",
      "\n",
      "MODEL\n",
      "Accuracy:  0.5452674897119342\n",
      "F1 Score:  0.6746171967020023\n"
     ]
    }
   ],
   "source": [
    "backtesting(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "MOMENTUM\n",
      "Accuracy:  0.5333333333333333\n",
      "F1 Score:  0.6315789473684211\n",
      "\n",
      "MODEL\n",
      "Accuracy:  0.5888888888888889\n",
      "F1 Score:  0.7412587412587412\n"
     ]
    }
   ],
   "source": [
    "backtesting(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "MOMENTUM\n",
      "Accuracy:  0.5333333333333333\n",
      "F1 Score:  0.6315789473684211\n",
      "\n",
      "MODEL\n",
      "Accuracy:  0.5666666666666667\n",
      "F1 Score:  0.7194244604316546\n"
     ]
    }
   ],
   "source": [
    "backtesting(RidgeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "MOMENTUM\n",
      "Accuracy:  0.5333333333333333\n",
      "F1 Score:  0.6315789473684211\n",
      "\n",
      "MODEL\n",
      "Accuracy:  0.5347736625514403\n",
      "F1 Score:  0.6349103826901341\n"
     ]
    }
   ],
   "source": [
    "backtesting(SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "MOMENTUM\n",
      "Accuracy:  0.5333333333333333\n",
      "F1 Score:  0.6315789473684211\n",
      "\n",
      "MODEL\n",
      "Accuracy:  0.6111111111111112\n",
      "F1 Score:  0.7586206896551725\n"
     ]
    }
   ],
   "source": [
    "backtesting(MLPClassifier(solver='lbfgs', alpha=1e-5, activation='relu',\n",
    "                          hidden_layer_sizes=(5, 2), random_state=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
